"""
YOLO ê¸°ë°˜ ë¬¸ì„œ ë ˆì´ì•„ì›ƒ ë° í‘œ ê°ì§€ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ YOLO ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬:
1. ë¬¸ì„œ ì´ë¯¸ì§€ì—ì„œ ë ˆì´ì•„ì›ƒ ìš”ì†Œ ê°ì§€ (í‘œ, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë“±)
2. íŠ¹íˆ í‘œ(Table) ì˜ì—­ì„ ì •ë°€í•˜ê²Œ íƒì§€
3. ê°ì§€ëœ ì˜ì—­ì˜ ì¢Œí‘œ(ë°”ìš´ë”© ë°•ìŠ¤)ë¥¼ ë°˜í™˜
"""

import os
from typing import List, Dict, Tuple, Optional
from pathlib import Path

import torch
import numpy as np
from ultralytics import YOLO

from src.utils import get_device


class LayoutDetector:
    """
    ë¬¸ì„œ ë ˆì´ì•„ì›ƒ ê°ì§€ë¥¼ ìœ„í•œ YOLO ëª¨ë¸ ë˜í¼ í´ë˜ìŠ¤

    ì£¼ìš” ê¸°ëŠ¥:
    - YOLO ëª¨ë¸ ë¡œë“œ ë° ì´ˆê¸°í™”
    - ë¬¸ì„œ ì´ë¯¸ì§€ì—ì„œ ë ˆì´ì•„ì›ƒ ìš”ì†Œ ê°ì§€
    - í‘œ ì˜ì—­ë§Œ í•„í„°ë§
    - ê°ì§€ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë°˜í™˜
    """

    def __init__(
        self,
        model_path: str = "yolo11n.pt",
        device: Optional[str] = None,
        confidence_threshold: float = 0.5
    ):
        """
        LayoutDetector ì´ˆê¸°í™”

        Args:
            model_path: YOLO ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
                - "yolo11n.pt": ì‚¬ì „í•™ìŠµëœ YOLO11 nano ëª¨ë¸ (ê°€ë²¼ì›€)
                - "yolo11s.pt", "yolo11m.pt" ë“±: ë” í° ëª¨ë¸ (ì •í™•ë„ ë†’ìŒ)
                - ì»¤ìŠ¤í…€ í•™ìŠµ ëª¨ë¸ ê²½ë¡œë„ ê°€ëŠ¥
            device: ì‹¤í–‰ ë””ë°”ì´ìŠ¤ ("mps", "cpu" ë“±)
                - Noneì´ë©´ ìë™ìœ¼ë¡œ ìµœì  ë””ë°”ì´ìŠ¤ ì„ íƒ
            confidence_threshold: ê°ì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0~1)
                - ì´ ê°’ë³´ë‹¤ ë‚®ì€ ì‹ ë¢°ë„ì˜ ê°ì§€ëŠ” ë¬´ì‹œë¨

        ì„¤ëª…:
            - YOLO ëª¨ë¸ì€ ê°ì²´ ê°ì§€(Object Detection)ë¥¼ ìˆ˜í–‰
            - ì´ë¯¸ì§€ â†’ ë°”ìš´ë”© ë°•ìŠ¤ + í´ë˜ìŠ¤ + ì‹ ë¢°ë„ ì¶œë ¥
        """
        self.device = device if device else get_device()
        self.confidence_threshold = confidence_threshold

        print(f"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
        self.model = YOLO(model_path)

        # ëª¨ë¸ì„ ì§€ì •ëœ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        # MPS ì‚¬ìš© ì‹œ GPU ê°€ì†ìœ¼ë¡œ ë¹ ë¥¸ ì¶”ë¡  ê°€ëŠ¥
        self.model.to(self.device)
        print(f"âœ“ ëª¨ë¸ì´ {self.device}ì— ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤")

        # ëª¨ë¸ í´ë˜ìŠ¤ ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…)
        if hasattr(self.model, 'names'):
            print(f"âœ“ ëª¨ë¸ í´ë˜ìŠ¤: {list(self.model.names.values())}")

    def detect(
        self,
        image_path: str,
        target_classes: Optional[List[str]] = None
    ) -> List[Dict]:
        """
        ì´ë¯¸ì§€ì—ì„œ ë ˆì´ì•„ì›ƒ ìš”ì†Œë¥¼ ê°ì§€í•©ë‹ˆë‹¤.

        Args:
            image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
            target_classes: í•„í„°ë§í•  í´ë˜ìŠ¤ ëª©ë¡ (ì˜ˆ: ["table"])
                - Noneì´ë©´ ëª¨ë“  í´ë˜ìŠ¤ ë°˜í™˜
                - ["table"]ì´ë©´ í‘œë§Œ ë°˜í™˜

        Returns:
            List[Dict]: ê°ì§€ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸
                ê° í•­ëª©ì€ ë‹¤ìŒ êµ¬ì¡°:
                {
                    "class": "table",              # í´ë˜ìŠ¤ëª…
                    "confidence": 0.95,            # ì‹ ë¢°ë„ (0~1)
                    "bbox": [x1, y1, x2, y2],     # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
                    "bbox_norm": [x1, y1, x2, y2] # ì •ê·œí™”ëœ ì¢Œí‘œ (0~1)
                }

        ì„¤ëª…:
            - self.model.predict(): YOLO ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰
            - ê²°ê³¼ëŠ” ultralyticsì˜ Results ê°ì²´ë¡œ ë°˜í™˜ë¨
            - boxes.xyxy: ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ [x1, y1, x2, y2]
            - boxes.conf: ì‹ ë¢°ë„ ì ìˆ˜
            - boxes.cls: í´ë˜ìŠ¤ ID
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

        # YOLO ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰
        # verbose=False: ì§„í–‰ ë©”ì‹œì§€ ìˆ¨ê¹€
        results = self.model.predict(
            source=image_path,
            device=self.device,
            conf=self.confidence_threshold,
            verbose=False
        )

        # ê²°ê³¼ íŒŒì‹±
        detections = []
        result = results[0]  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ê²°ê³¼ (ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)

        # ê°ì§€ëœ ê° ê°ì²´ì— ëŒ€í•´ ì²˜ë¦¬
        for box in result.boxes:
            # í´ë˜ìŠ¤ëª… ê°€ì ¸ì˜¤ê¸°
            class_id = int(box.cls[0])
            class_name = result.names[class_id]

            # target_classes í•„í„°ë§
            if target_classes and class_name not in target_classes:
                continue

            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ
            xyxy = box.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2]
            confidence = float(box.conf[0])

            # ì •ê·œí™”ëœ ì¢Œí‘œ (ì´ë¯¸ì§€ í¬ê¸° ëŒ€ë¹„ 0~1 ë²”ìœ„)
            img_height, img_width = result.orig_shape
            xyxy_norm = [
                xyxy[0] / img_width,
                xyxy[1] / img_height,
                xyxy[2] / img_width,
                xyxy[3] / img_height,
            ]

            detection = {
                "class": class_name,
                "confidence": confidence,
                "bbox": xyxy.tolist(),
                "bbox_norm": xyxy_norm,
            }
            detections.append(detection)

        print(f"âœ“ {len(detections)}ê°œ ê°ì²´ ê°ì§€ë¨ (ì´ë¯¸ì§€: {Path(image_path).name})")
        return detections

    def detect_tables(self, image_path: str) -> List[Dict]:
        """
        ì´ë¯¸ì§€ì—ì„œ í‘œ(Table) ì˜ì—­ë§Œ ê°ì§€í•©ë‹ˆë‹¤.

        Args:
            image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ

        Returns:
            List[Dict]: ê°ì§€ëœ í‘œ ë¦¬ìŠ¤íŠ¸

        ì„¤ëª…:
            - detect() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ë˜ target_classes=["Table"]ë¡œ í•„í„°ë§
            - DocLayNetì€ ëŒ€ë¬¸ì "Table" í´ë˜ìŠ¤ ì‚¬ìš©
        """
        # DocLayNet ëª¨ë¸ì€ "Table" (ëŒ€ë¬¸ì) í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©
        # ì†Œë¬¸ì/ëŒ€ë¬¸ì ëª¨ë‘ ì§€ì›í•˜ë„ë¡ ìˆ˜ì •
        all_detections = self.detect(image_path, target_classes=None)

        # ëª¨ë“  ê°ì§€ëœ í´ë˜ìŠ¤ ì¶œë ¥ (ë””ë²„ê¹…)
        detected_classes = set([d["class"] for d in all_detections])
        if detected_classes:
            print(f"  ê°ì§€ëœ í´ë˜ìŠ¤: {detected_classes}")

        # "Table" ë˜ëŠ” "table" í´ë˜ìŠ¤ë§Œ í•„í„°ë§
        table_detections = [
            d for d in all_detections
            if d["class"].lower() == "table"
        ]

        if not table_detections and all_detections:
            print(f"  âš ï¸  í‘œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í´ë˜ìŠ¤ê°€ ê°ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            print(f"  ğŸ’¡ ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš”: --conf 0.3")

        return table_detections

    def batch_detect(
        self,
        image_dir: str,
        output_dir: Optional[str] = None,
        target_classes: Optional[List[str]] = None
    ) -> Dict[str, List[Dict]]:
        """
        ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

        Args:
            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ì €ì¥ ì•ˆ í•¨)
            target_classes: í•„í„°ë§í•  í´ë˜ìŠ¤ ëª©ë¡

        Returns:
            Dict[str, List[Dict]]: {íŒŒì¼ëª…: ê°ì§€ê²°ê³¼} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬

        ì„¤ëª…:
            - ë””ë ‰í† ë¦¬ ë‚´ .png, .jpg, .jpeg íŒŒì¼ì„ ëª¨ë‘ ì²˜ë¦¬
            - ê° íŒŒì¼ì˜ ê°ì§€ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
        """
        image_dir_path = Path(image_dir)
        if not image_dir_path.exists():
            raise FileNotFoundError(f"ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")

        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        image_extensions = [".png", ".jpg", ".jpeg", ".PNG", ".JPG", ".JPEG"]
        image_files = [
            f for f in image_dir_path.iterdir()
            if f.suffix in image_extensions
        ]

        if not image_files:
            print(f"âš  {image_dir}ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return {}

        print(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(image_files)}ê°œ íŒŒì¼")

        results = {}
        for image_file in image_files:
            detections = self.detect(str(image_file), target_classes)
            results[image_file.name] = detections

        print(f"âœ“ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
        return results


def crop_detected_regions(
    image_path: str,
    detections: List[Dict],
    output_dir: str
) -> List[str]:
    """
    ê°ì§€ëœ ì˜ì—­ì„ ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ì˜ë¼ë‚´ì–´ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
        detections: detect() ë©”ì„œë“œì˜ ë°˜í™˜ê°’
        output_dir: ì˜ë¼ë‚¸ ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬

    Returns:
        List[str]: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸

    ì„¤ëª…:
        - í‘œ ì˜ì—­ì„ ì˜ë¼ë‚´ì–´ ë³„ë„ ì´ë¯¸ì§€ë¡œ ì €ì¥
        - OCR ì²˜ë¦¬ ì „ì— í‘œ ì˜ì—­ë§Œ ì¶”ì¶œí•˜ëŠ” ë° ì‚¬ìš©
    """
    import cv2

    if not os.path.exists(image_path):
        raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

    image = cv2.imread(image_path)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    cropped_paths = []
    base_name = Path(image_path).stem

    for idx, detection in enumerate(detections):
        bbox = detection["bbox"]
        x1, y1, x2, y2 = map(int, bbox)

        # ì´ë¯¸ì§€ í¬ë¡­
        cropped = image[y1:y2, x1:x2]

        # ì €ì¥ ê²½ë¡œ ìƒì„±
        class_name = detection["class"]
        filename = f"{base_name}_{class_name}_{idx:03d}.png"
        save_path = output_path / filename

        cv2.imwrite(str(save_path), cropped)
        cropped_paths.append(str(save_path))

    print(f"âœ“ {len(cropped_paths)}ê°œ ì˜ì—­ ì €ì¥: {output_dir}")
    return cropped_paths
